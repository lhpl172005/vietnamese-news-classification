{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8241d813-02c4-4cb1-a9ef-bdf1f968cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ ƒë·ªçc file th√†nh c√¥ng v·ªõi encoding UTF-8:\n",
      "   Unnamed: 0.1  Unnamed: 0      id      author  \\\n",
      "0             0           0  218270         NaN   \n",
      "1             1           1  218269  do√£n h·∫±ng    \n",
      "2             2           2  218268         NaN   \n",
      "3             3           3  218267         NaN   \n",
      "4             4           4  218266      mi lan   \n",
      "\n",
      "                                             content  picture_count  \\\n",
      "0  Chi·ªÅu 31/7, C√¥ng an t·ªânh Th·ª´a Thi√™n - Hu·∫ø th√¥n...              3   \n",
      "1  G·∫ßn ƒë√¢y, Th·ª© tr∆∞·ªüng B·ªô Ph√°t tri·ªÉn K·ªπ thu·∫≠t s·ªë,...              1   \n",
      "2  K·∫øt thi nghi·ªáp THPT 2022 trung b√¨nh m√¥n to√°n, ...              3   \n",
      "3  Th·ªëng ƒë·ªëc Kentucky Andy Beshear h√¥m 31/7 ƒë·ª£t m...              1   \n",
      "4  V·ª• tai n·∫°n giao th√¥ng li√™n ho√†n ph·ªë ƒëi Tam B·∫°c...             12   \n",
      "\n",
      "   processed        source                                              title  \\\n",
      "0          0     docbao.vn  T√™n c∆∞·ªõp ti·ªám v√†ng Hu·∫ø ƒë·∫°i u√Ω c√¥ng an, c√¥ng t√°...   \n",
      "1          0        vtc.vn                   B·ªè m·∫°ng 5G, Nga ti·∫øn th·∫≥ng 4G 6G   \n",
      "2          0  thanhnien.vn  ƒê·ªãa ph∆∞∆°ng ƒë·ª©ng ƒë·∫ßu t·ªïng 3 m√¥n vƒÉn, to√°n, ngo·∫°...   \n",
      "3          0     vnexpress                Ng∆∞·ªùi ch·∫øt m∆∞a l≈© 'ngh√¨n m·ªôt' M·ªπ 28   \n",
      "4          0          soha  H·∫£i Ph√≤ng: H√¨nh ·∫£nh xe \"ƒëi√™n\" tai n·∫°n li√™n ho√†...   \n",
      "\n",
      "                 topic                                                url  \\\n",
      "0            Ph√°p lu·∫≠t  https://docbao.vn/phap-luat/ten-cuop-tiem-vang...   \n",
      "1  S·ª©c kh·ªèe - ƒê·ªùi s·ªëng  https://vtc.vn/bo-qua-mang-5g-nga-tien-thang-t...   \n",
      "2             Gi√°o d·ª•c  https://thanhnien.vn/dia-phuong-nao-dung-dau-c...   \n",
      "3             Th·∫ø gi·ªõi  https://vnexpress.net/nguoi-chet-trong-mua-lu-...   \n",
      "4              Th·ªùi s·ª±  https://soha.vn/hai-phong-hinh-anh-xe-dien-gay...   \n",
      "\n",
      "                   crawled_at  \n",
      "0  2022-08-01 09:09:22.817308  \n",
      "1  2022-08-01 09:09:21.181469  \n",
      "2  2022-08-01 09:09:15.311901  \n",
      "3  2022-08-01 09:09:02.211498  \n",
      "4  2022-08-01 09:09:01.601170  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'Fixed_news_dataset.csv' \n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    \n",
    "    # In ra 5 d√≤ng ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra\n",
    "    print(\"ƒê√£ ƒë·ªçc file th√†nh c√¥ng v·ªõi encoding UTF-8:\")\n",
    "    print(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"C√≥ l·ªói x·∫£y ra: {e}\")\n",
    "    print(\"H√£y ki·ªÉm tra l·∫°i t√™n file ho·∫∑c ƒë∆∞·ªùng d·∫´n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4330432-548a-4fea-81ae-aebcc5c3d014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb0f341-a6c2-4715-a2a2-169e3c91684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu sau khi ch·ªâ gi·ªØ l·∫°i 2 c·ªôt v√† x√≥a d√≤ng thi·∫øu:\n",
      "                                             content                topic\n",
      "0  Chi·ªÅu 31/7, C√¥ng an t·ªânh Th·ª´a Thi√™n - Hu·∫ø th√¥n...            Ph√°p lu·∫≠t\n",
      "1  G·∫ßn ƒë√¢y, Th·ª© tr∆∞·ªüng B·ªô Ph√°t tri·ªÉn K·ªπ thu·∫≠t s·ªë,...  S·ª©c kh·ªèe - ƒê·ªùi s·ªëng\n",
      "2  K·∫øt thi nghi·ªáp THPT 2022 trung b√¨nh m√¥n to√°n, ...             Gi√°o d·ª•c\n",
      "3  Th·ªëng ƒë·ªëc Kentucky Andy Beshear h√¥m 31/7 ƒë·ª£t m...             Th·∫ø gi·ªõi\n",
      "4  V·ª• tai n·∫°n giao th√¥ng li√™n ho√†n ph·ªë ƒëi Tam B·∫°c...              Th·ªùi s·ª±\n"
     ]
    }
   ],
   "source": [
    "# 1. Ch·ªçn ra 2 c·ªôt c·∫ßn thi·∫øt\n",
    "df = df[['content', 'topic']]\n",
    "\n",
    "# 2. X√≥a c√°c d√≤ng c√≥ gi√° tr·ªã b·ªã thi·∫øu (n·∫øu c√≥)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# In ra ƒë·ªÉ xem k·∫øt qu·∫£\n",
    "print(\"D·ªØ li·ªáu sau khi ch·ªâ gi·ªØ l·∫°i 2 c·ªôt v√† x√≥a d√≤ng thi·∫øu:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd4328b-582c-4b89-b73c-1bd284a0e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√¢u g·ªëc: 'Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Machine Learning, h√¥m nay tr·ªùi ƒë·∫πp qu√°!!!'\n",
      "C√¢u sau khi x·ª≠ l√Ω: 'ch√†o_m·ª´ng machine learning h√¥m_nay tr·ªùi ƒë·∫πp'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "# --- T·∫£i danh s√°ch stopwords ---\n",
    "stopwords_path = 'vietnamese-stopwords.txt'\n",
    "try:\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.read().splitlines()\n",
    "except FileNotFoundError:\n",
    "    print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file stopwords t·∫°i '{stopwords_path}'.\")\n",
    "    print(\"H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ t·∫£i file v√† ƒë·∫∑t ƒë√∫ng v√†o th∆∞ m·ª•c d·ª± √°n.\")\n",
    "    stopwords = [] # D√πng danh s√°ch r·ªóng n·∫øu kh√¥ng t√¨m th·∫•y file\n",
    "\n",
    "# --- X√¢y d·ª±ng h√†m ti·ªÅn x·ª≠ l√Ω ---\n",
    "def preprocess_text(text):\n",
    "    # 1. Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. X√≥a c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát, s·ªë, v√† d·∫•u c√¢u nh∆∞ng gi·ªØ l·∫°i ti·∫øng Vi·ªát\n",
    "    text = re.sub(r'[^\\s\\w√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]', ' ', text)\n",
    "    \n",
    "    # 3. T√°ch t·ª´\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    \n",
    "    # 4. Lo·∫°i b·ªè stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# In th·ª≠ k·∫øt qu·∫£ c·ªßa h√†m v·ªõi m·ªôt c√¢u m·∫´u\n",
    "sample_text = \"Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Machine Learning, h√¥m nay tr·ªùi ƒë·∫πp qu√°!!!\"\n",
    "processed_sample = preprocess_text(sample_text)\n",
    "print(f\"C√¢u g·ªëc: '{sample_text}'\")\n",
    "print(f\"C√¢u sau khi x·ª≠ l√Ω: '{processed_sample}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408357bd-f521-43b7-8d86-96bc73680f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω...\n",
      "Ho√†n th√†nh!\n",
      "                                             content                topic  \\\n",
      "0  Chi·ªÅu 31/7, C√¥ng an t·ªânh Th·ª´a Thi√™n - Hu·∫ø th√¥n...            Ph√°p lu·∫≠t   \n",
      "1  G·∫ßn ƒë√¢y, Th·ª© tr∆∞·ªüng B·ªô Ph√°t tri·ªÉn K·ªπ thu·∫≠t s·ªë,...  S·ª©c kh·ªèe - ƒê·ªùi s·ªëng   \n",
      "2  K·∫øt thi nghi·ªáp THPT 2022 trung b√¨nh m√¥n to√°n, ...             Gi√°o d·ª•c   \n",
      "3  Th·ªëng ƒë·ªëc Kentucky Andy Beshear h√¥m 31/7 ƒë·ª£t m...             Th·∫ø gi·ªõi   \n",
      "4  V·ª• tai n·∫°n giao th√¥ng li√™n ho√†n ph·ªë ƒëi Tam B·∫°c...              Th·ªùi s·ª±   \n",
      "\n",
      "                                     cleaned_content  \n",
      "0  chi·ªÅu 31 7 c√¥ng_an t·ªânh th·ª´a thi√™n hu·∫ø th√¥ng b...  \n",
      "1  th·ª©_tr∆∞·ªüng ph√°t_tri·ªÉn k·ªπ_thu·∫≠t_s·ªë truy·ªÅn_th√¥ng...  \n",
      "2  k·∫øt_thi nghi·ªáp thpt 2022 trung_b√¨nh m√¥n to√°n n...  \n",
      "3  th·ªëng_ƒë·ªëc kentucky andy beshear h√¥m 31 7 ƒë·ª£t m...  \n",
      "4  v·ª• tai_n·∫°n giao_th√¥ng li√™n_ho√†n ph·ªë ƒëi tam b·∫°c...  \n"
     ]
    }
   ],
   "source": [
    "# √Åp d·ª•ng h√†m preprocess_text cho c·ªôt 'content'\n",
    "print(\"B·∫Øt ƒë·∫ßu qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω...\")\n",
    "df['cleaned_content'] = df['content'].apply(preprocess_text)\n",
    "print(\"Ho√†n th√†nh!\")\n",
    "\n",
    "# Xem k·∫øt qu·∫£ sau khi c√≥ th√™m c·ªôt m·ªõi 'cleaned_content'\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80bf95e9-7272-4bd9-8632-639e8ff66093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu bi·∫øn ƒë·ªïi d·ªØ li·ªáu train b·∫±ng TF-IDF...\n",
      "B·∫Øt ƒë·∫ßu bi·∫øn ƒë·ªïi d·ªØ li·ªáu test...\n",
      "Ho√†n th√†nh!\n",
      "K√≠ch th∆∞·ªõc c·ªßa ma tr·∫≠n train (s·ªë t√†i li·ªáu, s·ªë t·ª´ v·ª±ng): (128974, 259302)\n",
      "K√≠ch th∆∞·ªõc c·ªßa ma tr·∫≠n test (s·ªë t√†i li·ªáu, s·ªë t·ª´ v·ª±ng): (32244, 259302)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. T√°ch d·ªØ li·ªáu th√†nh X (ƒë·∫∑c tr∆∞ng) v√† y (nh√£n)\n",
    "X = df['cleaned_content']\n",
    "y = df['topic']\n",
    "\n",
    "# 2. Chia d·ªØ li·ªáu th√†nh t·∫≠p train v√† test (t·ª∑ l·ªá 80/20)\n",
    "# random_state=42 gi√∫p k·∫øt qu·∫£ chia lu√¥n gi·ªëng nhau m·ªói l·∫ßn ch·∫°y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Kh·ªüi t·∫°o v√† √°p d·ª•ng TF-IDF\n",
    "# Kh·ªüi t·∫°o TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# H·ªçc t·ª´ v·ª±ng t·ª´ t·∫≠p train v√† bi·∫øn ƒë·ªïi X_train th√†nh ma tr·∫≠n TF-IDF\n",
    "print(\"B·∫Øt ƒë·∫ßu bi·∫øn ƒë·ªïi d·ªØ li·ªáu train b·∫±ng TF-IDF...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Ch·ªâ bi·∫øn ƒë·ªïi X_test d·ª±a tr√™n t·ª´ v·ª±ng ƒë√£ h·ªçc t·ª´ t·∫≠p train\n",
    "print(\"B·∫Øt ƒë·∫ßu bi·∫øn ƒë·ªïi d·ªØ li·ªáu test...\")\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "print(\"Ho√†n th√†nh!\")\n",
    "\n",
    "# 4. In ra k√≠ch th∆∞·ªõc c·ªßa ma tr·∫≠n k·∫øt qu·∫£\n",
    "print(f\"K√≠ch th∆∞·ªõc c·ªßa ma tr·∫≠n train (s·ªë t√†i li·ªáu, s·ªë t·ª´ v·ª±ng): {X_train_tfidf.shape}\")\n",
    "print(f\"K√≠ch th∆∞·ªõc c·ªßa ma tr·∫≠n test (s·ªë t√†i li·ªáu, s·ªë t·ª´ v·ª±ng): {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a097920-d1ca-4706-b156-8a4ad6fc890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh Naive Bayes...\n",
      "ƒê√£ hu·∫•n luy·ªán xong!\n",
      "B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n tr√™n t·∫≠p test...\n",
      "ƒê√£ d·ª± ƒëo√°n xong!\n",
      "------------------------------\n",
      "üéâ ƒê·ªô ch√≠nh x√°c (Accuracy) c·ªßa m√¥ h√¨nh l√†: 64.75%\n",
      "------------------------------\n",
      "B√°o c√°o ph√¢n lo·∫°i chi ti·∫øt (Classification Report):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               B·∫°n ƒë·ªçc       0.00      0.00      0.00       344\n",
      "          B·∫•t ƒë·ªông s·∫£n       0.00      0.00      0.00       303\n",
      "             Ch√≠nh tr·ªã       1.00      0.01      0.01       779\n",
      "             C√¥ng ngh·ªá       0.88      0.11      0.19       837\n",
      "              Gi√°o d·ª•c       0.84      0.52      0.64      1539\n",
      "Kinh doanh - T√†i ch√≠nh       0.56      0.63      0.60      2066\n",
      "               Kinh t·∫ø       0.00      0.00      0.00      1036\n",
      "           PhaÃÅp lu√¢Ã£t       0.00      0.00      0.00         1\n",
      "             Ph√°p lu·∫≠t       0.76      0.76      0.76      2121\n",
      "            Qu·ªëc ph√≤ng       0.00      0.00      0.00       198\n",
      "   S·ª©c kh·ªèe - ƒê·ªùi s·ªëng       0.53      0.81      0.64      4637\n",
      "              Th·∫ø gi·ªõi       0.75      0.85      0.80      3255\n",
      "              Th·ªÉ thao       0.98      0.96      0.97      3840\n",
      "               Th·ªùi s·ª±       0.45      0.44      0.45      3117\n",
      "    VƒÉn h√≥a - Gi·∫£i tr√≠       0.71      0.83      0.77      4328\n",
      "                    Xe       0.93      0.38      0.54       755\n",
      "                X√£ h·ªôi       0.42      0.51      0.46      3088\n",
      "\n",
      "              accuracy                           0.65     32244\n",
      "             macro avg       0.52      0.40      0.40     32244\n",
      "          weighted avg       0.64      0.65      0.62     32244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "D:\\Python\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "D:\\Python\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Kh·ªüi t·∫°o v√† Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "print(\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh Naive Bayes...\")\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"ƒê√£ hu·∫•n luy·ªán xong!\")\n",
    "\n",
    "# 2. D·ª± ƒëo√°n tr√™n t·∫≠p test\n",
    "print(\"B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n tr√™n t·∫≠p test...\")\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"ƒê√£ d·ª± ƒëo√°n xong!\")\n",
    "\n",
    "# 3. ƒê√°nh gi√° m√¥ h√¨nh\n",
    "# T√≠nh to√°n ƒë·ªô ch√≠nh x√°c t·ªïng th·ªÉ\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-\" * 30)\n",
    "print(f\"üéâ ƒê·ªô ch√≠nh x√°c (Accuracy) c·ªßa m√¥ h√¨nh l√†: {accuracy * 100:.2f}%\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# In ra b√°o c√°o chi ti·∫øt cho t·ª´ng th·ªÉ lo·∫°i\n",
    "print(\"B√°o c√°o ph√¢n lo·∫°i chi ti·∫øt (Classification Report):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade3e9f-9aff-4def-aaaf-7305394d12db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
